{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVRuXFslo9b9"
      },
      "outputs": [],
      "source": [
        "%pip install transformers\n",
        "%pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubXVrpbvo9cB"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA--WSn4o9cB"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmGVpPRAo9cB"
      },
      "outputs": [],
      "source": [
        "model = \"Xingxian123/VaxLLM\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0ShWNGgo9cB"
      },
      "outputs": [],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "\"text-generation\",\n",
        "      model=model,\n",
        "      torch_dtype=torch.float16,\n",
        "      device = device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD5xsgn0o9cC"
      },
      "outputs": [],
      "source": [
        "def read_and_split_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "    # Split content into sections based on the separator line\n",
        "    sections = content.split(\"=\"*80)\n",
        "    return [section.strip() for section in sections if section.strip()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC9RyC79ecP8"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "\n",
        "# Set up pipeline\n",
        "pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0,\n",
        ")\n",
        "\n",
        "# Step 1: Classification\n",
        "classification_instruction = \"\"\"\n",
        "Task: Using the following data, is this article about a brucella vaccine? To classify an article as being about a brucella vaccine, you must successfully extract at least some information about the vaccine formulation. This includes details such as the antigen, protein, gene, adjuvant, or vaccine platform mentioned in the abstract.\n",
        "\"\"\"\n",
        "\n",
        "annotation_instruction = \"\"\"\n",
        "Task: Extract the following details using the given data: Vaccine Introduction,Vaccine Antigen, Vaccine Type, Vaccine Formulation, Host Species Used as Laboratory Animal Model, Experiment Used to investigate the vaccine Ensure each response is based solely on the provided data. Ensure the response is formatted as follows:\n",
        "\"\"\"\n",
        "\n",
        "response_template = \"\"\"\n",
        "Response:\n",
        "Vaccine Introduction:\n",
        "Vaccine Type:\n",
        "Vaccine Antigen:\n",
        "Vaccine Formulation:\n",
        "Host Species Used as Laboratory Animal Model:\n",
        "Experiment Used to investigate the vaccine:\n",
        "\"\"\"\n",
        "\n",
        "# Open a file to save the output\n",
        "output_file_path = \"/content/classification_results.txt\"\n",
        "\n",
        "with open(output_file_path, \"w\") as file:\n",
        "    # Loop through sections of the file\n",
        "    for section in read_and_split_file(\"/content/brucellosis_vaccine_papers.txt\"):\n",
        "        # Step 1: Classification\n",
        "        classification_prompt = f\"\"\"\n",
        "        {classification_instruction}\n",
        "\n",
        "        Data: {section}\n",
        "        \"\"\"\n",
        "\n",
        "        classification_result = pipeline(\n",
        "            classification_prompt,\n",
        "            do_sample=False,\n",
        "            num_return_sequences=1,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            truncation=True,\n",
        "            max_new_tokens=10,  # Limit tokens since we only need 'Yes' or 'No'\n",
        "        )\n",
        "\n",
        "        # Check if the model classified the article as relevant\n",
        "        is_brucella = \"yes\" in classification_result[0]['generated_text'].lower()\n",
        "        file.write(classification_result[0]['generated_text'] + \"\\n\")\n",
        "        print (\"complete classfication\")\n",
        "\n",
        "        if is_brucella:\n",
        "            # Step 2: Annotation\n",
        "            annotation_prompt = f\"\"\"\n",
        "            {annotation_instruction}\n",
        "\n",
        "            Data: {section}\n",
        "\n",
        "            {response_template}\n",
        "            \"\"\"\n",
        "\n",
        "            annotation_result = pipeline(\n",
        "                annotation_prompt,\n",
        "                do_sample=False,\n",
        "                #top_k=10,\n",
        "                #temperature=0.7,\n",
        "                num_return_sequences=1,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                truncation=True,\n",
        "                max_new_tokens=256,\n",
        "            )\n",
        "\n",
        "            file.write(annotation_result[0]['generated_text'] + \"\\n\")\n",
        "            file.write(\"=\" * 80 + \"\\n\")\n",
        "            print (\"complete annotation\")\n",
        "        else:\n",
        "            file.write(f\"Data: {section}\\n\")\n",
        "            file.write(\"Article is not about a Brucella vaccine.\\n\")\n",
        "            file.write(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "print(f\"Classification results saved to {output_file_path}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}